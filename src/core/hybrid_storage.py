#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
@ProjectName: homalos-datacenter
@FileName   : hybrid_storage.py
@Date       : 2025/10/27
@Author     : Lumosylva
@Email      : donnymoving@gmail.com
@Software   : PyCharm
@Description: æ··åˆå­˜å‚¨ - æ™ºèƒ½è·¯ç”±SQLiteï¼ˆçƒ­æ•°æ®ï¼‰å’ŒCSVï¼ˆå†·æ•°æ®ï¼Œå»¶è¿Ÿå‹ç¼©ï¼‰
"""
import threading
import time
from collections import deque
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime  # noqa: F401  (ä¿ç•™ç”¨äºæœªæ¥çš„æŸ¥è¯¢åŠŸèƒ½)
from typing import Optional

import pandas as pd

# æ–°å¢ï¼šDuckDB + å¤šçº¿ç¨‹CSVå†™å…¥å™¨
from src.core.duckdb_storage import DuckDBSingleFileWriter
from src.core.event import Event, EventType
from src.core.event_bus import EventBus
from src.core.object import TickData
from src.core.partitioned_csv_writer import PartitionedCSVWriter
from src.system_config import Config
from src.utils.log import get_logger


class HybridStorage:
    """
    æ··åˆå­˜å‚¨ - æ™ºèƒ½è·¯ç”±SQLiteå’ŒCSVå½’æ¡£ï¼ˆå»¶è¿Ÿå‹ç¼©ï¼‰
    
    å­˜å‚¨ç­–ç•¥ï¼š
    1. çƒ­æ•°æ®ï¼ˆè¿‘7å¤©ï¼‰ï¼šå†™å…¥SQLite + CSVæœªå‹ç¼©å½’æ¡£ï¼ˆäº¤æ˜“æ—¶é—´é«˜æ€§èƒ½ï¼‰
    2. å†·æ•°æ®ï¼ˆ7å¤©å‰ï¼‰ï¼šCSVå½’æ¡£ï¼ˆéäº¤æ˜“æ—¶é—´æ‰¹é‡å‹ç¼©ä¸ºtar.gzï¼‰
    
    æŸ¥è¯¢ç­–ç•¥ï¼š
    1. æŸ¥è¯¢è¿‘7å¤©æ•°æ®ï¼šä»SQLiteæŸ¥è¯¢ï¼ˆå¿«é€Ÿï¼‰
    2. æŸ¥è¯¢å†å²æ•°æ®ï¼šä»CSVå½’æ¡£æŸ¥è¯¢ï¼ˆéœ€è¦æ—¶è‡ªåŠ¨è§£å‹ï¼‰
    3. è·¨è¶Šæ—¶é—´æ®µï¼šåˆå¹¶SQLiteå’ŒCSVç»“æœ
    
    å‹ç¼©ç­–ç•¥ï¼š
    - äº¤æ˜“æ—¶é—´ï¼šå†™å…¥æœªå‹ç¼©CSVï¼Œæ€§èƒ½æœ€ä¼˜
    - éäº¤æ˜“æ—¶é—´ï¼šæ•´ä¸ªäº¤æ˜“æ—¥æ–‡ä»¶å¤¹æ‰“åŒ…ä¸ºtar.gzï¼Œå‹ç¼©ç‡æ›´é«˜
    """
    
    def __init__(self,
                 event_bus: Optional[EventBus] = None,
                 parquet_tick_path: str = "data/csv/ticks",
                 parquet_kline_path: str = "data/csv/klines",
                 retention_days: int = 7,
                 flush_interval: Optional[int] = None,  # ä»é…ç½®æ–‡ä»¶è¯»å–
                 max_buffer_size: Optional[int] = None,  # ä»é…ç½®æ–‡ä»¶è¯»å–
                 buffer_warning_threshold: Optional[float] = None,  # ä»é…ç½®æ–‡ä»¶è¯»å–
                 buffer_flush_threshold: Optional[float] = None,  # ä»é…ç½®æ–‡ä»¶è¯»å–
                 trading_day_manager = None):
        """
        åˆå§‹åŒ–æ··åˆå­˜å‚¨
        
        Args:
            event_bus: äº‹ä»¶æ€»çº¿ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™è‡ªåŠ¨è®¢é˜… TICK äº‹ä»¶ï¼‰
            parquet_tick_path: Tick CSVæ–‡ä»¶è·¯å¾„
            parquet_kline_path: Kçº¿ CSVæ–‡ä»¶è·¯å¾„
            retention_days: SQLiteæ•°æ®ä¿ç•™å¤©æ•°
            flush_interval: å®šæ—¶åˆ·æ–°é—´éš”ï¼ˆç§’ï¼‰ï¼ŒNoneæ—¶ä»é…ç½®æ–‡ä»¶è¯»å–
            max_buffer_size: ç¼“å†²åŒºä¸Šé™ï¼ŒNoneæ—¶ä»é…ç½®æ–‡ä»¶è¯»å–
            buffer_warning_threshold: è­¦å‘Šé˜ˆå€¼ï¼ŒNoneæ—¶ä»é…ç½®æ–‡ä»¶è¯»å–
            buffer_flush_threshold: æå‰åˆ·æ–°é˜ˆå€¼ï¼ŒNoneæ—¶ä»é…ç½®æ–‡ä»¶è¯»å–
            trading_day_manager: äº¤æ˜“æ—¥ç®¡ç†å™¨
        """
        self.logger = get_logger(self.__class__.__name__)
        
        # ğŸ”¥ ä»é…ç½®æ–‡ä»¶è¯»å–å‚æ•°ï¼ˆå¦‚æœæœªæ˜¾å¼ä¼ å…¥ï¼‰
        flush_interval = flush_interval if flush_interval is not None else Config.storage_flush_interval
        max_buffer_size = max_buffer_size if max_buffer_size is not None else Config.storage_max_buffer_size
        buffer_warning_threshold = buffer_warning_threshold if buffer_warning_threshold is not None else Config.storage_buffer_warning_threshold
        buffer_flush_threshold = buffer_flush_threshold if buffer_flush_threshold is not None else Config.storage_buffer_flush_threshold
        
        # ğŸ”¥ DuckDBå­˜å‚¨å±‚ï¼ˆæé€ŸæŸ¥è¯¢å¼•æ“ï¼‰- ä»é…ç½®æ–‡ä»¶è¯»å–æ‰¹é‡é˜ˆå€¼
        self.duckdb_tick_writer = DuckDBSingleFileWriter(
            db_path="data/duckdb/ticks",
            batch_threshold=Config.duckdb_tick_batch_threshold,  # ğŸ”¥ ä»é…ç½®è¯»å–
            data_type="ticks",
            trading_day_manager=trading_day_manager
        )
        
        self.duckdb_kline_writer = DuckDBSingleFileWriter(
            db_path="data/duckdb/klines",
            batch_threshold=Config.duckdb_kline_batch_threshold,  # ğŸ”¥ ä»é…ç½®è¯»å–
            data_type="klines",
            trading_day_manager=trading_day_manager
        )
        
        # ğŸ”¥ CSVå¤šçº¿ç¨‹å†™å…¥å™¨ï¼ˆé«˜ååå½’æ¡£ï¼‰- ä»é…ç½®æ–‡ä»¶è¯»å–æ‰¹é‡é˜ˆå€¼
        self.csv_tick_writer = PartitionedCSVWriter(
            base_path=parquet_tick_path,
            num_threads=Config.csv_num_threads,  # ğŸ”¥ ä»é…ç½®è¯»å–
            batch_threshold=Config.csv_tick_batch_threshold,  # ğŸ”¥ ä»é…ç½®è¯»å–
            queue_max_size=Config.csv_queue_max_size,  # ğŸ”¥ ä»é…ç½®è¯»å–
            trading_day_manager=trading_day_manager
        )
        
        self.csv_kline_writer = PartitionedCSVWriter(
            base_path=parquet_kline_path,
            num_threads=Config.csv_num_threads,  # ğŸ”¥ ä»é…ç½®è¯»å–
            batch_threshold=Config.csv_kline_batch_threshold,  # ğŸ”¥ ä»é…ç½®è¯»å–
            queue_max_size=Config.csv_queue_max_size,  # ğŸ”¥ ä»é…ç½®è¯»å–
            trading_day_manager=trading_day_manager
        )
        
        self.retention_days = retention_days
        self.flush_interval = flush_interval
        self.max_buffer_size = max_buffer_size
        self.buffer_warning_threshold = buffer_warning_threshold
        self.buffer_flush_threshold = buffer_flush_threshold
        
        # è®¡ç®—å®é™…é˜ˆå€¼ï¼ˆæ¡æ•°ï¼‰
        self._warning_size = int(max_buffer_size * buffer_warning_threshold)
        self._flush_size = int(max_buffer_size * buffer_flush_threshold)
        
        # ç¼“å†²åŒºé”ï¼ˆä¿æŠ¤å¹¶å‘è®¿é—®ï¼Œé˜²æ­¢æ•°æ®ä¸¢å¤±ï¼‰
        self._buffer_lock = threading.Lock()
        
        # Tick æ•°æ®ç¼“å†²åŒº
        self.tick_buffer: deque[TickData] = deque()
        
        # ç»Ÿè®¡è®¡æ•°å™¨
        self._tick_recv_count = 0
        
        # å®šæ—¶åˆ·æ–°çº¿ç¨‹
        self._flush_thread: Optional[threading.Thread] = None
        self._stop_flush = threading.Event()
        
        # ğŸ”¥ ä¿®å¤çº¿ç¨‹æ³„æ¼ï¼šä½¿ç”¨çº¿ç¨‹æ± ä»£æ›¿åˆ›å»ºæ–°çº¿ç¨‹
        self._save_executor = ThreadPoolExecutor(
            max_workers=2,  # æœ€å¤š2ä¸ªå¹¶å‘ä¿å­˜çº¿ç¨‹
            thread_name_prefix="HybridStorage-Saver"
        )
        
        # ä¿å­˜ EventBus å¼•ç”¨ï¼ˆç”¨äº stop æ—¶å–æ¶ˆè®¢é˜…ï¼‰
        self.event_bus = event_bus
        
        # å¯åŠ¨å®šæ—¶åˆ·æ–°çº¿ç¨‹
        self._start_flush_thread()
        
        # å¦‚æœæä¾›äº†äº‹ä»¶æ€»çº¿ï¼Œè®¢é˜… TICK äº‹ä»¶
        if event_bus:
            event_bus.subscribe(EventType.TICK, self._on_tick)
            self.logger.info(
                f"å·²è®¢é˜… TICK äº‹ä»¶ï¼Œå®šæ—¶åˆ·æ–°: {flush_interval}ç§’ï¼Œ"
                f"ç¼“å†²åŒº: {max_buffer_size}æ¡ï¼ˆâš ï¸{self._warning_size} / ğŸŸ¡{self._flush_size} / ğŸ”´{max_buffer_size}ï¼‰"
            )
        
        self.logger.info(
            f"æ··åˆå­˜å‚¨åˆå§‹åŒ–å®Œæˆï¼ŒSQLiteä¿ç•™{retention_days}å¤©ï¼Œ"
            f"ä¸‰çº§é˜ˆå€¼ç­–ç•¥: âš ï¸è­¦å‘Š{int(buffer_warning_threshold*100)}% / "
            f"ğŸŸ¡æå‰åˆ·æ–°{int(buffer_flush_threshold*100)}% / ğŸ”´ç´§æ€¥åˆ·æ–°100%"
        )
    
    def _start_flush_thread(self) -> None:
        """å¯åŠ¨å®šæ—¶åˆ·æ–°çº¿ç¨‹"""
        self._stop_flush.clear()
        self._flush_thread = threading.Thread(
            target=self._flush_worker,
            name="HybridStorage-FlushWorker",
            daemon=True
        )
        self._flush_thread.start()
        self.logger.info(f"å®šæ—¶åˆ·æ–°çº¿ç¨‹å·²å¯åŠ¨ï¼Œé—´éš”: {self.flush_interval}ç§’")
    
    def _flush_worker(self) -> None:
        """å®šæ—¶åˆ·æ–°å·¥ä½œçº¿ç¨‹ï¼ˆå¢åŠ å¥åº·æ£€æŸ¥ï¼‰"""
        last_flush_time = time.time()
        last_health_check = time.time()  # æ–°å¢
        
        while not self._stop_flush.is_set():
            try:
                current_time = time.time()
                
                # æ–°å¢ï¼šå®šæœŸå¥åº·æ£€æŸ¥ï¼ˆæ¯5åˆ†é’Ÿï¼‰
                if current_time - last_health_check >= 300.0:
                    try:
                        health = self.get_health_metrics()
                        self.logger.info(
                            f"ç³»ç»Ÿå¥åº·æ£€æŸ¥ï¼š{health['health_status']} | "
                            f"çº¿ç¨‹: {health['threads']['total_active']} "
                            f"(å·¥ä½œçº¿ç¨‹: {health['threads']['worker_count']}) | "
                            f"DuckDBç¼“å†²: Tick={health['duckdb']['tick_buffered']} "
                            f"KLine={health['duckdb']['kline_buffered']} | "
                            f"CSVé˜Ÿåˆ—: Tick={health['csv']['tick_queued']} "
                            f"KLine={health['csv']['kline_queued']} | "
                            f"Tickç¼“å†²: {health['buffer']['tick_buffer_usage_pct']}%"
                        )
                        last_health_check = current_time
                    except Exception as e:
                        self.logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥ï¼š{e}")
                
                # åŸæœ‰çš„å®šæ—¶åˆ·æ–°é€»è¾‘
                elapsed = current_time - last_flush_time
                if elapsed >= self.flush_interval:
                    # å¿«é€Ÿé¢„æ£€æŸ¥ï¼ˆæ— é”ï¼‰ï¼šé¿å…åœ¨ç¼“å†²åŒºä¸ºç©ºæ—¶ä»ç„¶è·å–é”
                    # æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªæ— é”çš„å¿«é€Ÿæ£€æŸ¥ï¼Œå¯èƒ½ä¸å®Œå…¨å‡†ç¡®ï¼Œä½†å¯ä»¥å‡å°‘é”ç«äº‰
                    if len(self.tick_buffer) > 0:
                        # æŒé”æ£€æŸ¥å¹¶åˆ·æ–°ï¼ˆäºŒæ¬¡ç¡®è®¤ï¼‰
                        with self._buffer_lock:
                            buffer_size = len(self.tick_buffer)
                            if buffer_size > 0:
                                self.logger.info(
                                    f"â° å®šæ—¶è§¦å‘åˆ·æ–°ï¼Œç¼“å†²åŒº: {buffer_size} æ¡Tick"
                                )
                                self._flush_tick_buffer_locked()
                    
                    # æ— è®ºæ˜¯å¦åˆ·æ–°ï¼Œéƒ½é‡ç½®å®šæ—¶å™¨ï¼ˆé¿å…ç´¯ç§¯å»¶è¿Ÿï¼‰
                    last_flush_time = current_time
                
                # çŸ­æš‚ä¼‘çœ ï¼ˆé¿å…CPUå ç”¨ï¼‰
                time.sleep(1)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                self.logger.error(f"å®šæ—¶åˆ·æ–°çº¿ç¨‹å¼‚å¸¸: {e}", exc_info=True)
                time.sleep(5)  # å¼‚å¸¸åç­‰å¾…5ç§’
    
    def stop(self) -> None:
        """
        åœæ­¢æ··åˆå­˜å‚¨ï¼ˆğŸ”¥ ä¼˜é›…å…³é—­åŒå±‚å­˜å‚¨ï¼‰
        
        å…³é—­é¡ºåºï¼š
        0. å–æ¶ˆè®¢é˜… TICK äº‹ä»¶ï¼ˆåœæ­¢æ¥æ”¶æ–°æ•°æ®ï¼‰
        1. åœæ­¢å®šæ—¶åˆ·æ–°çº¿ç¨‹
        2. åˆ·æ–°å‰©ä½™ç¼“å†²åŒº
        3. åœæ­¢DuckDBå†™å…¥å™¨
        4. åœæ­¢CSVå¤šçº¿ç¨‹å†™å…¥å™¨
        """
        self.logger.info("æ­£åœ¨åœæ­¢ HybridStorage...")
        
        # 0. ğŸ”¥ å–æ¶ˆè®¢é˜… TICK äº‹ä»¶ï¼ˆåœæ­¢æ¥æ”¶æ–°æ•°æ®ï¼‰
        if self.event_bus:
            self.event_bus.unsubscribe(EventType.TICK, self._on_tick)
            self.logger.info("âœ“ å·²å–æ¶ˆè®¢é˜… TICK äº‹ä»¶ï¼Œåœæ­¢æ¥æ”¶æ–°æ•°æ®")
        
        # 1. åœæ­¢å®šæ—¶åˆ·æ–°çº¿ç¨‹
        self._stop_flush.set()
        if self._flush_thread and self._flush_thread.is_alive():
            self._flush_thread.join(timeout=5.0)
            self.logger.info("âœ“ å®šæ—¶åˆ·æ–°çº¿ç¨‹å·²åœæ­¢")
        
        # 2. åˆ·æ–°å‰©ä½™ç¼“å†²åŒºï¼ˆæŒé”æ£€æŸ¥ï¼‰
        with self._buffer_lock:
            buffer_size = len(self.tick_buffer)
            if buffer_size > 0:
                self.logger.warning(
                    f"ä¼˜é›…å…³é—­ï¼šåˆ·æ–°å‰©ä½™ {buffer_size} æ¡Tick..."
                )
                self._flush_tick_buffer_locked()
                self.logger.info("âœ“ ç¼“å†²åŒºå·²åˆ·æ–°")
        
        # 3. ğŸ”¥ åœæ­¢DuckDBå†™å…¥å™¨ï¼ˆåˆ·æ–°æ‰€æœ‰å‰©ä½™æ•°æ®ï¼‰
        self.logger.info("åœæ­¢DuckDBå†™å…¥å™¨...")
        self.duckdb_tick_writer.stop()
        self.duckdb_kline_writer.stop()
        self.logger.info("âœ“ DuckDBå†™å…¥å™¨å·²åœæ­¢")
        
        # 4. ğŸ”¥ åœæ­¢CSVå¤šçº¿ç¨‹å†™å…¥å™¨ï¼ˆåˆ·æ–°æ‰€æœ‰é˜Ÿåˆ—ï¼‰
        self.logger.info("åœæ­¢CSVå†™å…¥å™¨...")
        self.csv_tick_writer.stop(timeout=30)
        self.csv_kline_writer.stop(timeout=30)
        self.logger.info("âœ“ CSVå†™å…¥å™¨å·²åœæ­¢")
        
        # 5. ğŸ”¥ å…³é—­ä¿å­˜çº¿ç¨‹æ± 
        self.logger.info("å…³é—­ä¿å­˜çº¿ç¨‹æ± ...")
        self._save_executor.shutdown(wait=True)  # Python 3.10 ä¸æ”¯æŒ timeout å‚æ•°
        self.logger.info("âœ“ ä¿å­˜çº¿ç¨‹æ± å·²å…³é—­")
        
        self.logger.info("âœ… HybridStorage å·²å®Œå…¨åœæ­¢ï¼ˆåŒå±‚å­˜å‚¨å·²ä¼˜é›…å…³é—­ï¼‰")
    
    def _on_tick(self, event: Event) -> None:
        """
        å¤„ç† TICK äº‹ä»¶ï¼ˆä¸‰çº§é˜ˆå€¼ç­–ç•¥ + é”ä¿æŠ¤ï¼‰
        
        Args:
            event: TICK äº‹ä»¶
            
        è§¦å‘ç­–ç•¥ï¼ˆä¸‰çº§é˜ˆå€¼ï¼‰ï¼š
            1. ä¸»ç­–ç•¥ï¼šå®šæ—¶åˆ·æ–°ï¼ˆæ¯60ç§’ï¼‰ - æ­£å¸¸è´Ÿè½½
            2. æå‰åˆ·æ–°ï¼šç¼“å†²åŒºè¾¾åˆ°85%æ—¶æå‰åˆ·æ–° - ä¸­é«˜è´Ÿè½½
            3. ç´§æ€¥åˆ·æ–°ï¼šç¼“å†²åŒºè¾¾åˆ°100%æ—¶ç´§æ€¥åˆ·æ–° - æé«˜è´Ÿè½½ï¼ˆå®‰å…¨é˜€ï¼‰
        
        çº¿ç¨‹å®‰å…¨ï¼š
            - ä½¿ç”¨ _buffer_lock ä¿æŠ¤ç¼“å†²åŒºçš„å¹¶å‘è®¿é—®
            - å¤åˆ¶+æ¸…ç©ºæ“ä½œåœ¨é”ä¿æŠ¤ä¸‹åŸå­æ‰§è¡Œ
            - å®é™…ä¿å­˜åœ¨åå°çº¿ç¨‹æ‰§è¡Œï¼Œé¿å…é˜»å¡Tickæ¥æ”¶
        """
        # âœ… ä¿®å¤ï¼šæ£€æŸ¥åœæ­¢æ ‡å¿—ï¼ˆæœ€æ—©è¿”å›ï¼Œé¿å…å¤„ç†æ•°æ®ï¼‰
        if self._stop_flush.is_set():
            return  # å¦‚æœå·²åœæ­¢ï¼Œç›´æ¥è¿”å›ï¼Œä¸å¤„ç†ä»»ä½•æ•°æ®
        
        try:
            # è§£æ Tick æ•°æ®
            payload = event.payload
            if not payload or "data" not in payload:
                self.logger.warning("æ”¶åˆ°ç©ºpayloadæˆ–ç¼ºå°‘dataå­—æ®µçš„TICKäº‹ä»¶")
                return
            
            tick: TickData = payload["data"]
            if not tick:
                self.logger.warning("TICKäº‹ä»¶ä¸­çš„dataä¸ºç©º")
                return
            
            # ===== ä¸´ç•ŒåŒºï¼šæ·»åŠ åˆ°ç¼“å†²åŒºå¹¶æ£€æŸ¥é˜ˆå€¼ =====
            with self._buffer_lock:
                self.tick_buffer.append(tick)
                buffer_size = len(self.tick_buffer)
                self._tick_recv_count += 1
                
                # ğŸ”´ ç´§æ€¥åˆ·æ–°ï¼ˆ100%ï¼‰ï¼šç¼“å†²åŒºå·²æ»¡ï¼ˆå®‰å…¨é˜€ï¼‰
                if buffer_size >= self.max_buffer_size:
                    buffer_usage = buffer_size / self.max_buffer_size * 100
                    self.logger.error(
                        f"ğŸ”´ ç¼“å†²åŒºå·²æ»¡ ({buffer_size}/{self.max_buffer_size} æ¡, {buffer_usage:.1f}%)ï¼Œ"
                        f"è§¦å‘ç´§æ€¥åˆ·æ–°ï¼ˆå®‰å…¨é˜€ï¼‰"
                    )
                    self._flush_tick_buffer_locked()
                    return
                
                # ğŸŸ¡ æå‰åˆ·æ–°ï¼ˆ85%ï¼‰ï¼šç¼“å†²åŒºæ¥è¿‘æ»¡ï¼ˆä¸»åŠ¨é˜²å¾¡ï¼‰
                if buffer_size >= self._flush_size:
                    buffer_usage = buffer_size / self.max_buffer_size * 100
                    self.logger.warning(
                        f"ğŸŸ¡ ç¼“å†²åŒºè¾¾åˆ°åˆ·æ–°é˜ˆå€¼ ({buffer_size}/{self.max_buffer_size} æ¡, {buffer_usage:.1f}%)ï¼Œ"
                        f"è§¦å‘æå‰åˆ·æ–°"
                    )
                    self._flush_tick_buffer_locked()
                    return
                
                # è­¦å‘Šï¼ˆ70%ï¼‰ï¼šç¼“å†²åŒºä½¿ç”¨ç‡åé«˜ï¼ˆä»…è®°å½•æ—¥å¿—ï¼Œæ¯1000æ¡æ‰“å°ä¸€æ¬¡ï¼‰
                if buffer_size >= self._warning_size:
                    if self._tick_recv_count % 1000 == 0:
                        buffer_usage = buffer_size / self.max_buffer_size * 100
                        self.logger.warning(
                            f"âš ï¸ ç¼“å†²åŒºä½¿ç”¨ç‡åé«˜ ({buffer_size}/{self.max_buffer_size} æ¡, {buffer_usage:.1f}%)ï¼Œ"
                            f"ç­‰å¾…å®šæ—¶åˆ·æ–°æˆ–æå‰åˆ·æ–°"
                        )
                    return
            
            # ===== æ­£å¸¸æ—¥å¿—ï¼ˆåœ¨ä¸´ç•ŒåŒºå¤–ï¼Œé¿å…æŒé”æ—¶é—´è¿‡é•¿ï¼‰=====
            if self._tick_recv_count % 1000 == 0:
                # å¿«é€Ÿè·å–ç¼“å†²åŒºå¤§å°
                with self._buffer_lock:
                    buffer_size = len(self.tick_buffer)
                buffer_usage = buffer_size / self.max_buffer_size * 100
                self.logger.info(
                    f"âœ“ HybridStorageå·²æ¥æ”¶ {self._tick_recv_count} æ¡Tick | "
                    f"ç¼“å†²åŒº: {buffer_size}/{self.max_buffer_size} ({buffer_usage:.1f}%)"
                )
        
        except Exception as e:
            self.logger.error(f"å¤„ç† TICK äº‹ä»¶å¤±è´¥: {e}", exc_info=True)
    
    def _flush_tick_buffer_locked(self) -> None:
        """
        åˆ·æ–° Tick ç¼“å†²åŒºï¼ˆæŒé”ç‰ˆæœ¬ï¼Œè°ƒç”¨å‰å¿…é¡»æŒæœ‰_buffer_lockï¼‰
        
        å…³é”®è®¾è®¡ï¼š
        1. å¤åˆ¶å¹¶æ¸…ç©ºç¼“å†²åŒºï¼ˆåŸå­æ“ä½œï¼Œåœ¨é”ä¿æŠ¤ä¸‹ï¼‰
        2. ç«‹å³é‡Šæ”¾é”ï¼ˆé¿å…é˜»å¡Tickæ¥æ”¶ï¼‰
        3. åœ¨åå°çº¿ç¨‹æ‰§è¡Œå®é™…ä¿å­˜ï¼ˆè€—æ—¶æ“ä½œï¼‰
        
        Note:
            - æ­¤æ–¹æ³•å¿…é¡»åœ¨æŒæœ‰_buffer_lockçš„æƒ…å†µä¸‹è°ƒç”¨
            - è°ƒç”¨è€…è´Ÿè´£æŒæœ‰é”ï¼Œæœ¬æ–¹æ³•ä¸åŠ é”
            - æ¸…ç©ºåçš„ç¼“å†²åŒºå¯ç«‹å³æ¥æ”¶æ–°Tickï¼Œä¸ä¼šä¸¢å¤±æ•°æ®
        """
        if not self.tick_buffer:
            return
        
        # ===== ä¸´ç•ŒåŒºï¼šå¤åˆ¶å¹¶æ¸…ç©ºï¼ˆåŸå­æ“ä½œï¼‰=====
        ticks_to_save = list(self.tick_buffer)
        self.tick_buffer.clear()
        # æ³¨æ„ï¼šæ­¤æ—¶é”ä»ç”±è°ƒç”¨è€…æŒæœ‰ï¼Œåœ¨withè¯­å¥ç»“æŸæ—¶è‡ªåŠ¨é‡Šæ”¾
        # æ¸…ç©ºåï¼Œæ–°çš„Tickå¯ä»¥ç«‹å³è¿›å…¥ç©ºç¼“å†²åŒºï¼Œä¸ä¼šä¸¢å¤±
        
        self.logger.info(f"â†’ å‡†å¤‡åˆ·æ–° {len(ticks_to_save)} æ¡Tickåˆ°å­˜å‚¨å±‚...")
        
        # ===== ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œä¿å­˜ï¼ˆé¿å…é˜»å¡Tickæ¥æ”¶ï¼Œé¿å…çº¿ç¨‹æ³„æ¼ï¼‰=====
        self._save_executor.submit(self._do_save_ticks, ticks_to_save)
    
    def _flush_tick_buffer(self) -> None:
        """åˆ·æ–° Tick ç¼“å†²åŒºåˆ°å­˜å‚¨å±‚ï¼ˆå…¼å®¹æ—§æ¥å£ï¼Œå†…éƒ¨åŠ é”ï¼‰"""
        with self._buffer_lock:
            self._flush_tick_buffer_locked()
    
    def _do_save_ticks(self, ticks_to_save: list[TickData]) -> None:
        """
        æ‰§è¡Œå®é™…çš„Tickæ•°æ®ä¿å­˜ï¼ˆåœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œï¼‰
        
        Args:
            ticks_to_save: å¾…ä¿å­˜çš„Tickæ•°æ®åˆ—è¡¨
        """
        try:
            self.logger.info(f"â†’ å¼€å§‹ä¿å­˜ {len(ticks_to_save)} æ¡Tickåˆ°å­˜å‚¨å±‚...")
            
            # å°† TickData å¯¹è±¡è½¬æ¢ä¸º DataFrameï¼ˆ47ä¸ªå­—æ®µï¼ŒPascalCaseå‘½åï¼‰
            tick_dicts = []
            for tick in ticks_to_save:
                # è½¬æ¢æ—¥æœŸæ ¼å¼ï¼šYYYYMMDD â†’ YYYY-MM-DDï¼ˆDuckDB DATEç±»å‹è¦æ±‚ï¼‰
                def format_date(date_str):
                    """å°†YYYYMMDDæ ¼å¼è½¬æ¢ä¸ºYYYY-MM-DD"""
                    if date_str and len(str(date_str)) == 8:
                        s = str(date_str)
                        return f"{s[:4]}-{s[4:6]}-{s[6:8]}"
                    return date_str
                
                # æ„å»º Timestampï¼ˆå®Œæ•´datetimeç”¨äºæ—¶é—´åºåˆ—æŸ¥è¯¢ï¼‰
                timestamp_val = None
                if tick.trading_day and tick.update_time:
                    try:
                        timestamp_val = pd.to_datetime(f"{tick.trading_day} {tick.update_time}.{tick.update_millisec:03d}")
                    except Exception as e:
                        # å›é€€åˆ°ç§’çº§ç²¾åº¦
                        timestamp_val = pd.to_datetime(f"{tick.trading_day} {tick.update_time}")
                        self.logger.warning(f"æ— æ³•å°†Tickæ—¶é—´è½¬æ¢ä¸ºå®Œæ•´datetime: {e}")
                
                # æŒ‰ç”¨æˆ·æŒ‡å®šçš„47ä¸ªå­—æ®µé¡ºåºï¼ˆPascalCaseå‘½åï¼‰
                tick_dict = {
                    # 1-2: åŸºç¡€æ—¶é—´ä¿¡æ¯
                    "TradingDay": format_date(tick.trading_day),  # è½¬æ¢ä¸ºYYYY-MM-DDæ ¼å¼
                    "ExchangeID": tick.exchange_id.value if tick.exchange_id else None,
                    
                    # 3-5: ä»·æ ¼ä¿¡æ¯
                    "LastPrice": tick.last_price,
                    "PreSettlementPrice": tick.pre_settlement_price,
                    "PreClosePrice": tick.pre_close_price,
                    
                    # 6-10: æˆäº¤æŒä»“
                    "PreOpenInterest": tick.pre_open_interest,
                    "OpenPrice": tick.open_price,
                    "HighestPrice": tick.highest_price,
                    "LowestPrice": tick.lowest_price,
                    "Volume": tick.volume,
                    
                    # 11-14: ç»Ÿè®¡æ•°æ®
                    "Turnover": tick.turnover,
                    "OpenInterest": tick.open_interest,
                    "ClosePrice": tick.close_price,
                    "SettlementPrice": tick.settlement_price,
                    
                    # 15-18: æ¶¨è·Œåœå’ŒDelta
                    "UpperLimitPrice": tick.upper_limit_price,
                    "LowerLimitPrice": tick.lower_limit_price,
                    "PreDelta": tick.pre_delta,
                    "CurrDelta": tick.curr_delta,
                    
                    # 19-20: æ›´æ–°æ—¶é—´
                    "UpdateTime": tick.update_time,
                    "UpdateMillisec": tick.update_millisec,
                    
                    # 21-24: ä¹°ä¸€æ¡£
                    "BidPrice1": tick.bid_price_1,
                    "BidVolume1": tick.bid_volume_1,
                    "AskPrice1": tick.ask_price_1,
                    "AskVolume1": tick.ask_volume_1,
                    
                    # 25-28: ä¹°å–äºŒæ¡£
                    "BidPrice2": tick.bid_price_2,
                    "BidVolume2": tick.bid_volume_2,
                    "AskPrice2": tick.ask_price_2,
                    "AskVolume2": tick.ask_volume_2,
                    
                    # 29-32: ä¹°å–ä¸‰æ¡£
                    "BidPrice3": tick.bid_price_3,
                    "BidVolume3": tick.bid_volume_3,
                    "AskPrice3": tick.ask_price_3,
                    "AskVolume3": tick.ask_volume_3,
                    
                    # 33-36: ä¹°å–å››æ¡£
                    "BidPrice4": tick.bid_price_4,
                    "BidVolume4": tick.bid_volume_4,
                    "AskPrice4": tick.ask_price_4,
                    "AskVolume4": tick.ask_volume_4,
                    
                    # 37-40: ä¹°å–äº”æ¡£
                    "BidPrice5": tick.bid_price_5,
                    "BidVolume5": tick.bid_volume_5,
                    "AskPrice5": tick.ask_price_5,
                    "AskVolume5": tick.ask_volume_5,
                    
                    # 41-47: å…¶ä»–ä¿¡æ¯å’Œæ—¶é—´æˆ³
                    "AveragePrice": tick.average_price,
                    "ActionDay": format_date(tick.action_day),  # è½¬æ¢ä¸ºYYYY-MM-DDæ ¼å¼
                    "InstrumentID": tick.instrument_id,
                    "ExchangeInstID": tick.exchange_inst_id,
                    "BandingUpperPrice": tick.banding_upper_price,
                    "BandingLowerPrice": tick.banding_lower_price,
                    "Timestamp": timestamp_val,
                }
                tick_dicts.append(tick_dict)
            
            df = pd.DataFrame(tick_dicts)
            
            # æ‰¹é‡ä¿å­˜
            self.save_ticks(df)
            
            self.logger.info(f"âœ“ å·²æ‰¹é‡ä¿å­˜ {len(tick_dicts)} æ¡ Tick æ•°æ®åˆ°å­˜å‚¨å±‚ï¼ˆåŒ…å«å®Œæ•´å­—æ®µï¼‰")
        
        except Exception as e:
            self.logger.error(f"åˆ·æ–° Tick ç¼“å†²åŒºå¤±è´¥: {e}", exc_info=True)
    
    def save_ticks(self, df: pd.DataFrame) -> None:
        """
        ä¿å­˜Tickæ•°æ®ï¼ˆğŸ”¥ åŒå±‚å­˜å‚¨ï¼šDuckDBæé€ŸæŸ¥è¯¢ + CSVå¤šçº¿ç¨‹å½’æ¡£ï¼‰
        
        Args:
            df: Tickæ•°æ®DataFrame
        
        æ–°æ¶æ„ï¼š
        1. DuckDBï¼šæé€ŸæŸ¥è¯¢å¼•æ“ï¼ˆå•çº¿ç¨‹å†™å…¥ï¼Œæ’åºèšç±»ï¼‰
        2. CSVï¼šé«˜ååå½’æ¡£ï¼ˆ4çº¿ç¨‹å¹¶è¡Œï¼Œå“ˆå¸Œåˆ†é…ï¼‰
        """
        if df.empty:
            return
        
        try:
            self.logger.info(f"  â†’ åŒå±‚å†™å…¥ {len(df)} æ¡Tick...")
            
            # æ’åºï¼ˆä¸ºDuckDBä¼˜åŒ–ï¼Œä¿è¯ç‰©ç†è¿ç»­æ€§ï¼‰
            # è¿™æ˜¯æ€§èƒ½çš„å…³é”®ï¼æ’åºåDuckDBçš„Zone Mapså¯ä»¥ç²¾ç¡®è£å‰ª
            df = df.sort_values(by=['InstrumentID', 'Timestamp']).reset_index(drop=True)
            
            # 1. å†™å…¥DuckDBï¼ˆæé€ŸæŸ¥è¯¢ï¼‰
            self.duckdb_tick_writer.submit_batch(df)
            self.logger.info("  âœ“ DuckDBå†™å…¥é˜Ÿåˆ—æäº¤æˆåŠŸ")
            
            # 2. å†™å…¥CSVï¼ˆå¤šçº¿ç¨‹å½’æ¡£ï¼‰
            self.csv_tick_writer.submit_batch(df)
            self.logger.info("  âœ“ CSVå¤šçº¿ç¨‹å†™å…¥é˜Ÿåˆ—æäº¤æˆåŠŸ")
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            duckdb_stats = self.duckdb_tick_writer.get_stats()
            csv_stats = self.csv_tick_writer.get_stats()
            
            self.logger.debug(
                f"  ç»Ÿè®¡ä¿¡æ¯ - "
                f"DuckDBç¼“å†²: {duckdb_stats['total_buffered']}æ¡ | "
                f"CSVé˜Ÿåˆ—: {csv_stats['total_queued']}æ¡"
            )
        
        except Exception as e:
            self.logger.error(f"åŒå±‚å†™å…¥Tickæ•°æ®å¤±è´¥: {e}", exc_info=True)
    
    def save_klines(self, df: pd.DataFrame) -> None:
        """
        ä¿å­˜Kçº¿æ•°æ®ï¼ˆåŒå±‚å­˜å‚¨ï¼šDuckDBæé€ŸæŸ¥è¯¢ + CSVå¤šçº¿ç¨‹å½’æ¡£ï¼‰
        
        Args:
            df: Kçº¿æ•°æ®DataFrameï¼ˆåŒ…å«æ ¸å¿ƒå­—æ®µï¼ŒPascalCaseå‘½åï¼‰
        """
        if df.empty:
            return
        
        try:
            # éªŒè¯å¿…è¦å­—æ®µï¼ˆPascalCaseå‘½åï¼‰
            required_cols = ["InstrumentID", "Timestamp"]
            if not all(col in df.columns for col in required_cols):
                self.logger.warning(f"Kçº¿æ•°æ®ç¼ºå°‘å¿…è¦å­—æ®µ: {required_cols}ï¼Œå®é™…å­—æ®µ: {df.columns.tolist()}")
                return
            
            self.logger.debug(f"  â†’ åŒå±‚å†™å…¥ {len(df)} æ¡Kçº¿...")
            
            # æ’åºï¼ˆä¸ºDuckDBä¼˜åŒ–ï¼‰
            df = df.sort_values(by=['InstrumentID', 'Timestamp']).reset_index(drop=True)
            
            # 1. å†™å…¥DuckDBï¼ˆæé€ŸæŸ¥è¯¢ï¼‰
            self.duckdb_kline_writer.submit_batch(df)
            self.logger.debug("  âœ“ DuckDB Kçº¿å†™å…¥é˜Ÿåˆ—æäº¤æˆåŠŸ")
            
            # 2. å†™å…¥CSVï¼ˆå¤šçº¿ç¨‹å½’æ¡£ï¼‰
            self.csv_kline_writer.submit_batch(df)
            self.logger.debug("  âœ“ CSV Kçº¿å¤šçº¿ç¨‹å†™å…¥é˜Ÿåˆ—æäº¤æˆåŠŸ")
        
        except Exception as e:
            self.logger.error(f"åŒå±‚å†™å…¥Kçº¿æ•°æ®å¤±è´¥: {e}", exc_info=True)
    
    def query_ticks(self,
                    instrument_id: str,
                    start_time: str,
                    end_time: str) -> pd.DataFrame:
        """
        æŸ¥è¯¢Tickæ•°æ®ï¼ˆTODO: éœ€è¦å®ç°DuckDBæŸ¥è¯¢å¼•æ“ï¼‰
        
        Args:
            instrument_id: åˆçº¦ä»£ç 
            start_time: å¼€å§‹æ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
            end_time: ç»“æŸæ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
        
        Returns:
            Tickæ•°æ®DataFrame
        
        Note:
            å½“å‰ç‰ˆæœ¬æš‚æœªå®ç°æŸ¥è¯¢åŠŸèƒ½ï¼Œéœ€è¦å®ç°DuckDBQueryEngine
            å‚è€ƒæ–‡æ¡£ï¼šdocs/DuckDBå­˜å‚¨æ–¹æ¡ˆæ€»ä½“è®¾è®¡.md
        """
        self.logger.warning(
            f"æŸ¥è¯¢Tickæ•°æ®åŠŸèƒ½æš‚æœªå®ç° [åˆçº¦: {instrument_id}, "
            f"æ—¶é—´: {start_time} ~ {end_time}]"
        )
        return pd.DataFrame()
    
    def query_klines(self,
                     instrument_id: str,
                     interval: str,
                     start_time: str,
                     end_time: str) -> pd.DataFrame:
        """
        æŸ¥è¯¢Kçº¿æ•°æ®ï¼ˆTODO: éœ€è¦å®ç°DuckDBæŸ¥è¯¢å¼•æ“ï¼‰
        
        Args:
            instrument_id: åˆçº¦ä»£ç 
            interval: Kçº¿å‘¨æœŸ
            start_time: å¼€å§‹æ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
            end_time: ç»“æŸæ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
        
        Returns:
            Kçº¿æ•°æ®DataFrame
        
        Note:
            å½“å‰ç‰ˆæœ¬æš‚æœªå®ç°æŸ¥è¯¢åŠŸèƒ½ï¼Œéœ€è¦å®ç°DuckDBQueryEngine
            å‚è€ƒæ–‡æ¡£ï¼šdocs/DuckDBå­˜å‚¨æ–¹æ¡ˆæ€»ä½“è®¾è®¡.md
        """
        self.logger.warning(
            f"æŸ¥è¯¢Kçº¿æ•°æ®åŠŸèƒ½æš‚æœªå®ç° [åˆçº¦: {instrument_id}, "
            f"å‘¨æœŸ: {interval}, æ—¶é—´: {start_time} ~ {end_time}]"
        )
        return pd.DataFrame()
    
    def get_statistics(self) -> dict:
        """
        è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ–°æ¶æ„ï¼šDuckDB + CSVï¼‰
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        # è·å–DuckDBå’ŒCSVå†™å…¥å™¨çš„ç»Ÿè®¡ä¿¡æ¯
        duckdb_tick_stats = self.duckdb_tick_writer.get_stats()
        duckdb_kline_stats = self.duckdb_kline_writer.get_stats()
        csv_tick_stats = self.csv_tick_writer.get_stats()
        csv_kline_stats = self.csv_kline_writer.get_stats()
        
        return {
            "storage_type": "hybrid (DuckDB + CSV åŒå±‚å­˜å‚¨)",
            "retention_days": self.retention_days,
            "duckdb": {
                "ticks": duckdb_tick_stats,
                "klines": duckdb_kline_stats
            },
            "csv": {
                "ticks": csv_tick_stats,
                "klines": csv_kline_stats
            }
        }
    
    def get_health_metrics(self) -> dict:
        """
        è·å–ç³»ç»Ÿå¥åº·æŒ‡æ ‡ï¼ˆæ–°å¢ç›‘æ§ï¼‰
        
        Returns:
            å¥åº·æŒ‡æ ‡å­—å…¸ï¼ŒåŒ…å«ï¼š
            - åå°çº¿ç¨‹æ•°é‡ï¼ˆä»…æ•°æ®ä¸­å¿ƒç›¸å…³çº¿ç¨‹ï¼‰
            - DuckDBé˜Ÿåˆ—çŠ¶æ€
            - CSVé˜Ÿåˆ—çŠ¶æ€
            - ç¼“å†²åŒºä½¿ç”¨ç‡
        """
        import threading
        
        # 1. ç›‘æ§åå°çº¿ç¨‹æ•°é‡ï¼ˆä»…æ•°æ®ä¸­å¿ƒç›¸å…³çº¿ç¨‹ï¼‰
        thread_list = threading.enumerate()
        thread_names = [t.name for t in thread_list]
        
        # âœ… ä¿®å¤ï¼šåªç»Ÿè®¡æ•°æ®ä¸­å¿ƒç›¸å…³çš„çº¿ç¨‹ï¼Œæ’é™¤ Uvicorn/FastAPI çº¿ç¨‹
        datacenter_keywords = [
            "Worker", "Saver", "Flush", "Pool", "DuckDB", "CSV",
            "EventBus", "SyncLoop", "Timer", "HybridStorage"
        ]
        
        datacenter_threads = []
        worker_threads = []
        
        for name in thread_names:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°æ®ä¸­å¿ƒç›¸å…³çº¿ç¨‹
            for keyword in datacenter_keywords:
                if keyword in name:
                    datacenter_threads.append(name)
                    # åŒæ—¶æ£€æŸ¥æ˜¯å¦æ˜¯å·¥ä½œçº¿ç¨‹
                    if any(k in name for k in ["Worker", "Saver", "Flush"]):
                        worker_threads.append(name)
                    break
        
        active_threads = len(datacenter_threads)  # âœ… åªç»Ÿè®¡æ•°æ®ä¸­å¿ƒçº¿ç¨‹
        
        # 2. ç›‘æ§DuckDBé˜Ÿåˆ—
        duckdb_tick_stats = self.duckdb_tick_writer.get_stats()
        duckdb_kline_stats = self.duckdb_kline_writer.get_stats()
        
        # 3. ç›‘æ§CSVé˜Ÿåˆ—å¤§å°
        csv_tick_stats = self.csv_tick_writer.get_stats()
        csv_kline_stats = self.csv_kline_writer.get_stats()
        
        # 4. ç¼“å†²åŒºä½¿ç”¨ç‡
        with self._buffer_lock:
            buffer_size = len(self.tick_buffer)
        buffer_usage = buffer_size / self.max_buffer_size * 100
        
        # 5. è¯„ä¼°å¥åº·çŠ¶æ€
        health_status = self._evaluate_health(
            active_threads, 
            duckdb_tick_stats.get('total_buffered', 0),
            csv_tick_stats.get('total_queued', 0),
            buffer_usage
        )
        
        return {
            "timestamp": datetime.now().isoformat(),
            "health_status": health_status,
            "threads": {
                "total_active": active_threads,
                "worker_count": len(worker_threads),
                "worker_names": worker_threads[:10]  # åªæ˜¾ç¤ºå‰10ä¸ª
            },
            "duckdb": {
                "tick_buffered": duckdb_tick_stats.get('total_buffered', 0),
                "kline_buffered": duckdb_kline_stats.get('total_buffered', 0),
                "tick_threshold": duckdb_tick_stats.get('batch_threshold', 0),
                "kline_threshold": duckdb_kline_stats.get('batch_threshold', 0)
            },
            "csv": {
                "tick_queued": csv_tick_stats.get('total_queued', 0),
                "kline_queued": csv_kline_stats.get('total_queued', 0),
                "tick_workers": csv_tick_stats.get('workers_alive', 0),
                "kline_workers": csv_kline_stats.get('workers_alive', 0),
                "queue_sizes": {
                    "tick": csv_tick_stats.get('queue_sizes', []),
                    "kline": csv_kline_stats.get('queue_sizes', [])
                }
            },
            "buffer": {
                "tick_buffer_size": buffer_size,
                "tick_buffer_max": self.max_buffer_size,
                "tick_buffer_usage_pct": round(buffer_usage, 2)
            }
        }

    @staticmethod
    def _evaluate_health(threads: int, duckdb_buf: int,
                         csv_queue: int, buffer_pct: float) -> str:
        """
        è¯„ä¼°ç³»ç»Ÿå¥åº·çŠ¶æ€
        
        Args:
            threads: æ•°æ®ä¸­å¿ƒçº¿ç¨‹æ•°ï¼ˆä¸åŒ…æ‹¬ Uvicorn/FastAPIï¼‰
            duckdb_buf: DuckDBç¼“å†²åŒºå¤§å°
            csv_queue: CSVé˜Ÿåˆ—å¤§å°
            buffer_pct: Tickç¼“å†²åŒºä½¿ç”¨ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
        
        Returns:
            å¥åº·çŠ¶æ€å­—ç¬¦ä¸²
        """
        # ä¸¥é‡ï¼ˆâœ… æ›´æ–°é˜ˆå€¼ï¼šåªç»Ÿè®¡æ•°æ®ä¸­å¿ƒçº¿ç¨‹ï¼Œæ­£å¸¸åº”è¯¥åœ¨80ä¸ªä»¥å†…ï¼‰
        if threads > 150:
            return "ğŸ”´ CRITICAL: æ•°æ®ä¸­å¿ƒçº¿ç¨‹æ•°è¿‡å¤š"
        if duckdb_buf > 200000:
            return "ğŸ”´ CRITICAL: DuckDBé˜Ÿåˆ—ä¸¥é‡ç§¯å‹"
        if csv_queue > 100000:
            return "ğŸ”´ CRITICAL: CSVé˜Ÿåˆ—ä¸¥é‡ç§¯å‹"
        if buffer_pct > 90:
            return "ğŸ”´ CRITICAL: Tickç¼“å†²åŒºæ¥è¿‘æ»¡è½½"
        
        # è­¦å‘Šï¼ˆâœ… æ›´æ–°é˜ˆå€¼ï¼šæ•°æ®ä¸­å¿ƒæ­£å¸¸çº¿ç¨‹æ•°çº¦70ä¸ªï¼Œ>100ä¸ºè­¦å‘Šï¼‰
        if threads > 100:
            return "ğŸŸ¡ WARNING: æ•°æ®ä¸­å¿ƒçº¿ç¨‹æ•°åé«˜"
        if duckdb_buf > 100000:
            return "ğŸŸ¡ WARNING: DuckDBé˜Ÿåˆ—ç§¯å‹"
        if csv_queue > 50000:
            return "ğŸŸ¡ WARNING: CSVé˜Ÿåˆ—ç§¯å‹"
        if buffer_pct > 70:
            return "ğŸŸ¡ WARNING: Tickç¼“å†²åŒºä½¿ç”¨ç‡åé«˜"
        
        # å¥åº·
        return "âœ… HEALTHY"

